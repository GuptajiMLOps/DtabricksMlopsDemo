name: Publish Code to Databricks Shared Folder
on: push
jobs:
  deploy-to-databricks:
    runs-on: ubuntu-latest
 
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
 
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.8'
 
      - name: Install Databricks CLI
        run: pip install databricks-cli
 
      - name: Publish Files to Databricks Workspace
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: |
          # Copy entire directory or specific files
          databricks workspace mkdirs /Shared/Mlops_Project
          databricks workspace import_dir ./ /Shared/Mlops_Project --overwrite
      - name: Run Notebook
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: |
          JOB_ID=$(databricks jobs create --json '{
            "name": "Execute My Notebook",
            "tasks": [{
              "task_key": "execute_notebook",
              "notebook_task": {
                "notebook_path": "/Shared/Mlops_Project/ML_End_to_END_Project.ipynb"
              }
            }]
          }' | jq -r '.job_id')
          RUN_ID=$(databricks jobs run-now --job-id $JOB_ID | jq -r '.run_id')
          echo "Notebooks job submitted. Monitor the run at $DATABRICKS_HOST#job/$JOB_ID/run/$RUN_ID"
